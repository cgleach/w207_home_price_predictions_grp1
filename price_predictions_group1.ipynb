{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Brainstorm and To-Do List:\n",
    "\n",
    "1) Each team member is going to take a shot at cleaning up the data.  Primarly concerned with conerting categorical variables to multiple dummy variables, and making sure no missing values\n",
    "\n",
    "2) Check to ensure no extreme outliers.  (Maybe do some quick .describe() and write up\n",
    "\n",
    "3) Two baselines:\n",
    "        * Linear regression (Or Lasso Regression)\n",
    "        * Some super simple rule of thumb (e.g. average price of all homes in neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import scipy\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical_to_dummy(df, columns = [], drop_first = True):\n",
    "    \"\"\"\n",
    "    Convert all categorical variables to k-1 dummy variables\n",
    "    \"\"\"\n",
    "    if len(columns) > 0:\n",
    "        new_df = pd.get_dummies(df, drop_first = drop_first, columns = columns)\n",
    "    else:\n",
    "        new_df = pd.get_dummies(df, drop_first = drop_frist)\n",
    "        \n",
    "    return new_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recession_indicator(row):\n",
    "    \"\"\"Take in sale date and return whether it was during recession\n",
    "    as determined by official statistics; only include the recession\n",
    "    which occured during years in question, but can expand as necessary\n",
    "    https://en.wikipedia.org/wiki/List_of_recessions_in_the_United_States\"\"\"\n",
    "    \n",
    "    period = date(row['YrSold'],row['MoSold'],1)\n",
    "    if (period >= date(2007,12,1)) & (period <= date(2009,6,1)) :\n",
    "        return 'recession'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert year based features to age; Most recent year is 2010, so we will treat that as year 0\n",
    "def convert_year_to_age(df, columns):\n",
    "    \"\"\"Helper function to convert year features into age assuming 2010 as year 0\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda x: (2010-x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['recession'] = train_df.apply(lambda x: recession_indicator(x), axis = 1)\n",
    "test_df['recession'] = test_df.apply(lambda x: recession_indicator(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns which we believe it makes sense to convert to boolean\n",
    "categorical_columns = ['MSSubClass','MSZoning','Street','Alley','LotShape','LandContour','Utilities','LotConfig',\n",
    "                       'LandSlope','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','RoofStyle',\n",
    "                       'RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond','Foundation',\n",
    "                       'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC',\n",
    "                       'CentralAir','Electrical','KitchenQual','Functional','FireplaceQu','GarageType','GarageFinish',\n",
    "                       'GarageQual','GarageCond','PavedDrive','PoolQC','Fence','MiscFeature','MoSold','SaleType',\n",
    "                       'SaleCondition','recession']\n",
    "\n",
    "new_train = convert_categorical_to_dummy(train_df,categorical_columns)\n",
    "new_test = convert_categorical_to_dummy(test_df,categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get missing columns in the training test\n",
    "missing_cols = set( new_train.columns ) - set( new_test.columns )\n",
    "\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for col in missing_cols:\n",
    "    new_test[col] = 0\n",
    "    \n",
    "# Ensure matching order and columns \n",
    "new_test = new_test[new_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error, SalePrice was not derived from a missing category\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure that our missing columns are only derived from the test data lacking specific instances\n",
    "# of a categorical variable.  Test data set will not have SalePrice (that's target variable Y) so we are alright\n",
    "for col in missing_cols:\n",
    "    if col.split(\"_\")[0] not in categorical_columns:\n",
    "        print(\"Error, %s was not derived from a missing category\" %col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Note: YrSold is different from the other year variables as for the first 3 converting year to age \n",
    "from 2010 is a logical conversion assuming linear depreciation (Being built 2 years ago should have twice the \n",
    "depreciation effect as 1 year ago, etc.).  However, for year sold we are only covering a 5 year period during which \n",
    "there was a significant shock to global financial markets.  As such we will not convert year sold to age,\n",
    "and opt instead to convert it to a categorical variable (see above)\"\"\"\n",
    "\n",
    "year_cols = ['YearBuilt','YearRemodAdd','GarageYrBlt']\n",
    "new_train = convert_year_to_age(new_train,year_cols)\n",
    "new_test = convert_year_to_age(new_test,year_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clayleach/p3env/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Use SKLearn scaling \n",
    "def min_max_scaling(df, columns):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    scaled_df = min_max_scaler.fit_transform(df)\n",
    "    scaled_df = pd.DataFrame(scaled_df,columns = columns)\n",
    "    return scaled_df, min_max_scaler\n",
    "\n",
    "# Opt for min-max scaling as opposed to mean normalization as we have so many boolean variables.  Min-Max\n",
    "# preserve the 0/1 nature of these features.  We may revisit using alternative scaling methods in future\n",
    "# iterations of preprocessing\n",
    "\n",
    "scaled_train, min_max_scaler_train = min_max_scaling(new_train, new_train.columns)\n",
    "scaled_train['Id'] = scaled_train.index + 1\n",
    "\n",
    "scaled_test = pd.DataFrame(min_max_scaler_train.transform(new_test),columns=new_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things we found interesting when evaluating data:\n",
    "\n",
    "1) Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling to do list:\n",
    "\n",
    "    1) Do all of the below both pre and post PCA\n",
    "\n",
    "    2) Do all of the below both pre and post k-means++ clustering\n",
    "\n",
    "Models:\n",
    "\n",
    "    1) Neural net (Feed Forward)\n",
    "\n",
    "    2) XGBoost (or RF)\n",
    "\n",
    "    3) GMM\n",
    "\n",
    "    4) SVM\n",
    "\n",
    "    5) KNN (Restrict what features we use)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA + GXBoost = Best | Clay & Rohini prediction\n",
    "# Lasso Regression     | Mark predicts this will be the hard to beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
